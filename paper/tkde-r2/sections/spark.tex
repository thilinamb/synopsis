\subsection{Use with Analytic Engines}
Synthetic data queries in \textsc{Synopsis} can be used to generate representative datasets that require less space while still providing high accuracy.  
Such datasets can be used efficiently with analytic engines such as Apache Spark \cite{zaharia2010spark} and TensorFlow \cite{tensorflow}.  
We used Spark to train regression models based on the Random Forest ensemble method to predict temperatures (in Kelvin) using surface visibility, humidity and precipitation in the southeast United States during the months of May--August, 2011--2014.
These models were generated using the original full-resolution data as well as synthetic data sets that were sized at 10\%, 20\%, and 100\% of the original data.
For another point of comparison, we also generated datasets using 10\% and 20\% samples of the original data.
The accuracy of these models was measured using a test dataset extracted from actual observations (30\% of the overall dataset size).
All five datasets were staged on HDFS and loaded into Spark to train the models.

We evaluated our approach based on the on-disk and in-memory storage requirements, data loading time, training time and the accuracy of the model.
Our observations are summarized in Table~\ref{tab:spark-rf}; overall, the accuracy of the synthetic data models is comparable to that of the actual data, while requiring less space, training, and loading times;
for instance, our 10\% synthetic dataset produces a model with similar accuracy while incurring 54\% less training time and reducing space requirements by 90\%. Additionally, based on the number of RDD partitions used, the smaller synthetic datasets require substantially less computing resources.  It is worth noting that these particular models do not appear to benefit from a larger set of training samples, and could potentially begin to exhibit over-fitting if trained on more data.
We believe signs of this are demonstrated by the 100\% synthetic dataset, where fidelity limits of the sketch result in training data that slightly reduces the expressiveness of the model.
%
\begin{table*}[ht!]
    \renewcommand{\arraystretch}{1.2}
    \caption{Comparing Random Forest based regression models generated by Spark MLlib using synthetic vs. real data \vspace{-1em}}
    \label{tab:spark-rf}
    \begin{center}
        \begin{tabularx}{\textwidth}{|X|c|c|c|c|c|c|c|c|}
            \hline
            \multirow{2}{*}{Dataset} & \multirow{2}{*}{Size (GB)} & \multirow{2}{*}{RDD Partitions} & \multicolumn{2}{c|}{\cellcolor[gray]{0.7}Data Loading Time (s)} &\multicolumn{2}{c|}{\cellcolor[gray]{0.7}Model Training Time (s)} & \multicolumn{2}{c|}{\cellcolor[gray]{0.7}Accuracy - RMSE (K)}\\
            \cline{4-9}
             & & & \cellcolor[gray]{0.9}Mean & \cellcolor[gray]{0.9}Std. Dev.  &  \cellcolor[gray]{0.9}Mean & \cellcolor[gray]{0.9}Std. Dev. &  \cellcolor[gray]{0.9}Mean & \cellcolor[gray]{0.9}Std. Dev. \\
            \hline
            Original & 25.350 & 208 & 28.035 & 2.249 & 506.493 & 9.500 & 5.981 & 0.027 \\
            \hline
            Original - 10\% Sample & 2.535 & 21 & 5.136 & 0.909 & 205.627 & 5.798 & 5.960  & 0.049 \\
            \hline
            Original - 20\% Sample & 5.069 & 41 & 6.102 & 1.607 & 216.857 & 7.994 & 5.994 & 0.026 \\
            \hline
            Synthetic - 10\% & 2.549 & 21 & 5.097 & 0.912 & 231.221 & 13.459 & 5.951 & 0.027 \\
            \hline
            Synthetic - 20\% & 5.098 & 41 & 6.208 & 0.637 & 235.018 & 16.148 & 5.981 & 0.051 \\
            \hline
            Synthetic - 100\% & 25.066 & 207 & 25.670 & 2.947 & 454.964 & 16.446 & 6.192 & 0.076 \\
            \hline
        \end{tabularx}
    \end{center}
    \vspace{-1em}
\end{table*}
