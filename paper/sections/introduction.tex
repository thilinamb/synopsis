\section{Introduction}
\label{sec:introduction}
The proliferation of remote sensing equipment (such as radars and satellites), networked sensors, commercial mapping, location-based services, and sales tracking techniques have all resulted in the exponential growth of spatiotemporal data. Spatiotemporal data comprise observations where both the location and time of measurement are made available in addition to \emph{features} of interest (such as humidity, air quality, disease prevalence, sales, etc). This information can be leveraged in several domains to inform decision making, scientific modeling, simulations, and resource allocation. Relevant domains include atmospheric science, epidemiology, environmental science, geosciences, smart-city settings, and commercial applications. In these settings, queries over the data must be \emph{expressive} to ensure efficient retrievals. Furthermore, query evaluations must be executed in real time and at high throughput, regardless of data volumes.

Spatiotemporal datasets are naturally multidimensional with multiple features of interest being reported/recorded continually for a particular timestamp and geolocation. The values associated with these features are continually changing; in other words, the dataset \emph{feature space} is always evolving.  Queries specified over these datasets may have a wide range of characteristics encompassing the frequency at which they are evaluated and their spatiotemporal scope. The crux of this paper is to support query evaluations over continually arriving observational data. The queries may be continuous or discrete, involve sliding windows, and encompass varying geospatial scopes.

\subsection{Challenges}
Support for real-time evaluation of queries --– discrete and continuous --– over a feature space that is continually evolving introduces unique challenges. These include:
\begin{itemize}
    \item   \emph{Data volumes:} It is infeasible to store all the observational data. This is especially true if the arrival rates outpace the rate at which data can be written to disk.
    \item   \emph{Data arrival rates:} The data may arrive continually and at high rates. Furthermore, this rate of arrivals may change over time.
    \item   \emph{Accuracy:} Queries specified by the user --- continuous or one-time --- must be accurate.
    \item   \emph{Continuous query evaluations:} Users should be able to register query evaluations over the observational space that are continually evaluated.
    \item   \emph{Spatiotemporal characteristics:} Queries may target spatiotemporal properties. For example, a user may be interested in feature characteristics for a geospatial location at a particular daily interval over a chronological range (for example, 2:00--4:00 pm over 2--3 months).
\end{itemize}

\subsection{Research Questions}
\begin{enumerate}
    \item   How can we generate compact, memory-resident representations of the observational space? These \emph{sketches} must be amenable to fast, continuous updates to ensure they are representative of the observational space.
    \item   How can we scale effectively in situations where the observations arrive at a rate faster than the rate at which the sketch can be updated? The density and arrival rates for observations vary based on the geospatial characteristics of the data. For example, in a smart-city setting, New York City would have a far higher rate of observations than a mid-sized city such as Denver, CO.
    \item   How can we effectively account for the spatiotemporal attributes associated with both the observations and the queries specified by the users? This spans the generation and updates of the sketch, scaling in response to high data arrival rates, and the evaluation of the queries.
    \item   How can we ensure high throughput in the assimilation of observations, updates to the sketch, and query evaluations? A particular challenge is preservation of accuracy in query evaluations despite high data arrivals, scaling in response to changes in system load, and concurrent query evaluations.  This encompasses using horizontal scaling to proactively alleviate hotspots, maintaining a distributed representation of the sketches, and effective distribution, targeting, and combining of query evaluations.
\end{enumerate}

\subsection{Methodology}
Our methodology targets: (1) creation of the distributed sketch, (2) updating the sketch in response to data arrivals, (3) identifying and alleviating performance hotspots, (4) support for splitting and fusing a sketch, and (5) dynamic creation of distributed sketch. (6) using the distributed sketch to perform query evaluations, and (7) achieve high-throughput by minimizing synchronization between different portions of the distributed sketch. 

Our sketch supports 3 key features. Specifically, the sketch (1) maintains a compact representation of the observations seen so far, (2) is amenable to splitting and fusing, and (3) supports query evaluations  including specification of sliding window sizes and geospatial scopes to support exploring properties of the observational space.  The sketch is naturally amenable to support distributed representations, with each node within the cluster holding information about the observational space. The distributed representation of the sketch is that of a dynamic, continually-updated in-memory store.

There are several advantages to a distributed representation of the sketch. (1) It allows us to maintain a richer (finer-grained) representation  of the feature space. (2) it improves accuracy during query evaluations, (3) supports multiple, concurrent query evaluations with each node evaluating queries independently.

Furthermore, at each node we dynamically adjust the representativeness of the sketch. There are two options here: bias towards the recent past or equal representations. In the former approach, the sketch targets finer-grained representations of observations in the recent past, and progressively coarser grained representations for the farther past. This scheme ensures that the apportioning of the available memory for the sketch is proportional to the time-intervals under consideration. For example, last 3 minutes, last 3 hours, last 3 days, last 3 months, last 3 years, and last 3 decades would have equal memory footprints.  In the latter approach, the sketch maintains a coarser-grained representations at each node.

The sketch scales (up or down) dynamically to cope with data arrival rates. At each node, the expressiveness of the sketch can be tuned dynamically based on the available memory. At each node, the sketch continually updates the expressiveness of the portions of the feature space, dynamically reorients the graph-based structure, and minimizes traversals (using Bloom Filters) to support faster evaluations and preserve high-throughput. 

\subsection{Paper Contributions}
In this paper we presented a framework for supporting real-time query evaluations over voluminous, time-series data streams. Our specific contributions include:
\begin{itemize}
\item   Design of a distributed sketch that maintains compact, distributed representations of the observational space. At each node, the sketch supports dynamic reorientations to conserve memory and support faster query evaluations.
\item   Support for dynamic scaling of the sketch in response to the data arrival rates. Upscaling operations support targeted alleviation of hotspots. Only geographic locations that are observing high data arrival rates are scale. The framework manages the complexity of identifying these hotspots, splitting the particular portion of the sketch, and migrating relevant portions of the sketch. Most importantly, the framework achieves this while maintaining acceptable levels of accuracy in query evaluations.
\item   Support for one-time and continuous evaluations of the observational space. We incorporate support for CQL queries. Query evaluations can target arbitrarily sized (chronological) window sizes and geospatial scopes.
\item   Support for high-throughput, distributed evaluation of queries.
To our knowledge, \textsc{Synopsis} is the first sketch designed specifically for geospatial observational data. We have validated the suitability of our approach through a comprehensive set of benchmarks with real observational data. 
\end{itemize}

\subsection{Paper Organization}
The remainder of this paper is organized as follows...


