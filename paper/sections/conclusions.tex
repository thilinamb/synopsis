\section{Conclusions and Future Work}
\label{sec:conclusions}
In this paper, we presented a framework for constructing a distributed sketch over spatiotemporal observational streams. \textsc{Synopsis} maintains a compact representation of the observational space, allows dynamic scaling in and out to preserve responsiveness and avoid overprovisioning, and supports a rich set of queries to explore the observational space. Our methodology for achieving this is broadly applicable to other stream processing systems.  Our empirical benchmarks, with real-world observational data, demonstrate the suitability of our approach.

We achieve compactness in our sketchlet instances by dynamically managing the number of vertices in the graph hierarchy as well as the size of the ranges each vertex is responsible for. We also maintain summary statistics and metadata within these vertices to track the distribution/dispersion of feature values and their frequencies. As a result, \textsc{Synopsis} is able to represent datasets using substantially less memory (\textbf{RQ-1}). Given variability in the rates and volumes of data arrivals from different geolocations, our scaling mechanism avoids overprovisioning and alleviates situations where sketch updates cannot keep pace with data arrival rates. Memory pressure is also taken into account during replica creation as well as scaling in and out (\textbf{RQ-2}).

(RQ3) \textsc{Synopsis} is spatially explicit, with nodes comprising distributed sketch responsible for managing particular geospatial scopes. Scaling decisions are localized to particular nodes and involve load shedding during scaling out and fusion during scaling in. Each \textsc{Synopsis} node also maintains a prefix tree that maintains compact information about the nodes managing geospatial scopes. At each node, the metadata graph maintains information about different chronological time ranges; the system maintains fine-grained information about recent data and coarser grained information about older, historical data. This structure supports incremental scaling, allows nodes to effectively assimilate observations at high rates, and redirect queries to nodes where they should be evaluated. Our graph based organization of the extracted metadata allows us to support a rich set of queries without compromising on timeliness; the accuracy of these evaluations is influenced by the granularity of the representations.  

(RQ4) Since we support targeted scaling in and out based on the data arrival rates and memory pressure, the assimilations and query evaluations can keep pace with the observations. During query evaluations,  only those \textsc{Synopsis} nodes that hold portions of the observational space implicitly or explicitly targeted by the query are involved in the query evaluations, and that to independently and without synchronizing with each other: this allows us to support high throughput query evaluations.

Our future work will target support for \textsc{Synopsis} to be used as input for long-running computations that are expressed as MapReduce jobs. Such jobs would execute periodically on a varying number of machines and could target the entire observational space or only the most recently-assimilated records.
