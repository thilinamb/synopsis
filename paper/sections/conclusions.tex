\section{Conclusions and Future Work}
\label{sec:conclusions}
In this paper, we presented a framework for constructing a distributed sketch over spatiotemporal observational streams. \textsc{Synopsis} maintains compact representation of the observational space, supports dynamic upscaling and downscaling to preserve responsiveness and avoid overprovisioning, and supports a rich set of queries to explore the observational space. Our methodology for achieving this is broadly applicable to other stream processing systems.  Our empirical benchmarks, with real-world observational data, demonstrate the suitability of our approach.We now make a set of assertions pertaining to the research questions that we explored in this study.
\begin{description}[leftmargin=*]
\item[RQ-1:] Extracting metadata from observational data streams as they come in. We then check to see if the sketch needs to be updated. Each vertex represents a range of values; 
We achieve compactness because the number of vertices in the graph is influenced by the number of ranges and how they are organized both of which are dynamically managed in \textsc{Synopsis} using density-driven quantization.  We also maintain summary statistics within these vertices to track the distribution/dispersion of feature values and the frequency with values fall within that range. Maintaining such summary statistics in an online fashion precludes the need to maintain fine-grained information that is memory intensive.

\item[RQ-2:] Data arrivals in observational settings are not uniform and the underlying infrastructure must be responsive to it.  There will be variability in the rates and volumes of data arrivals from different geolocations due to differences and flux in the number of sensing sources. \textsc{Synopsis} scaling mechanism avoid overprovisioning via targeted scaling of portions of \textsc{Synopsis}. 
Targeted scaling allows us to alleviate situations where sketch updates cannot keep pace with data arrival rates.  Memory pressure is also taken into account during upscaling, downscaling, and creation of spares. Since \textsc{Synopsis} is memory-resident (to avoid disk I/O costs) tracking strains induced either by nodes comprising the \textsc{Synopsis} distributed sketch or the collocated processes is critical.

Given the rates of data arrivals, reactive schemes for scaling would result in updates and query evaluations over portions of the feature space to be slow. Our proactive scaling scheme triggers dynamic upscaling and downscaling based on the expected data arrival rates and the accompanying memory footprints. Our distributed locking scheme avoid deadlocks and liveness issues during scaling operations.

\item[RQ-3:] \textsc{Synopsis} is spatially explicit, with nodes comprising distributed sketch responsible for managing particular geospatial scopes. Scaling decisions are localized to particular nodes and involve load shedding during upscaling and fusion during downscaling. Each \textsc{Synopsis} node also maintains a prefix tree that maintains compact information about the nodes managing geospatial scopes. At each node, the metadata graph maintains information about different chronological time ranges; the system maintains fine-grained information about recent data and coarser grained information about older, historical data. This structure supports incremental scaling, allows nodes to effectively assimilate observations at high rates, and redirect queries to nodes where they should be evaluated. Our graph based organization of the extracted metadata allows us to support a rich set of queries without compromising on timeliness; the accuracy of these evaluations is influenced by the granularity of the representations.  

\item[RQ-4:] Since we support targeted upscaling and downscaling based on the data arrival rates and memory pressure, the assimilations and query evaluations can keep pace with the observations. During query evaluations,  only those \textsc{Synopsis} nodes that hold portions of the observational space implicitly or explicitly targeted by the query are involved in the query evaluations, and that to independently and without synchronizing with each other: this allows us to support high throughput query evaluations.

Our future work will target support for \textsc{Synopsis} to be used as input for long-running computations that are expressed as MapReduce jobs. Such jobs that would execute periodically and on potentially varying number of machines could target the entire observational space or only the most recent ones.
\end{description}
