\subsection{Use with Analytic Engines}
Synthetic data queries in \textsc{Synopsis} can be used to generate representative datasets that require less space while still providing high accuracy.  
Such datasets can be used efficiently with analytic engines such as Apache Spark \cite{zaharia2010spark} and TensorFlow \cite{tensorflow}.  
We used Spark to train regression models based on the Random Forest ensemble method to predict temperatures (in Kelvin) using surface visibility, humidity and precipitation in the southeast United States during the months of May--August, 2011--2014.
These models were generated using the original full-resolution data as well as synthetic data sets that were sized at 10\% and 20\% of the original data.
The accuracy of these models was measured using a test dataset extracted from actual observations (30\% of the overall dataset size).
All three datasets were staged on HDFS and loaded into Spark to train the ensemble models.

We evaluated the efficacy of our approach based on the on-disk and in-memory storage requirements, data loading time, training time and the accuracy of the model.
Our observations are summarized in Table~\ref{tab:spark-rf}.
The accuracy of the models generated based on synthetic data is comparable to those of models generated using actual data, while requiring less space, training and loading times.
For instance, our 10\% synthetic dataset produces a model with similar accuracy incurring 54\% less training time while reducing space requirements by 90\%. Additionally, based on the number of RDD partitions used, the synthetic datasets require substantially less computing resources.
%
\begin{table*}[ht!]
    \renewcommand{\arraystretch}{1.2}
    \caption{Comparing Random Forest based regression models generated by Spark MLlib using synthetic vs. real data \vspace{-1em}}
    \label{tab:spark-rf}
    \begin{center}
        \begin{tabularx}{\textwidth}{|X|c|c|c|c|c|c|c|c|}
            \hline
            \multirow{2}{*}{Dataset} & \multirow{2}{*}{Size (GB)} & \multirow{2}{*}{RDD Partitions} & \multicolumn{2}{c|}{\cellcolor[gray]{0.7}Data Loading Time (s)} &\multicolumn{2}{c|}{\cellcolor[gray]{0.7}Model Training Time (s)} & \multicolumn{2}{c|}{\cellcolor[gray]{0.7}Accuracy - RMSE (K)}\\
            \cline{4-9}
             & & & \cellcolor[gray]{0.9}Mean & \cellcolor[gray]{0.9}Std. Dev.  &  \cellcolor[gray]{0.9}Mean & \cellcolor[gray]{0.9}Std. Dev. &  \cellcolor[gray]{0.9}Mean & \cellcolor[gray]{0.9}Std. Dev. \\
            \hline
            Original & 25.350 & 208 & 28.035 & 2.249 & 506.493 & 9.500 & 5.981 & 0.027 \\
            \hline
            Original - 10\% Sample & 2.535 & 21 & 5.136 & 0.909 & 205.627 & 5.798 & 5.960  & 0.049 \\
            \hline
            Original - 20\% Sample & 5.069 & 41 & 6.102 & 1.607 & 216.857 & 7.994 & 5.994 & 0.026 \\
            \hline
            Synthetic - 10\% & 2.549 & 21 & 5.097 & 0.912 & 231.221 & 13.459 & 5.951 & 0.027 \\
            \hline
            Synthetic - 20\% & 5.098 & 41 & 6.208 & 0.637 & 235.018 & 16.148 & 5.981 & 0.051 \\
            \hline
        \end{tabularx}
    \end{center}
    \vspace{-1em}
\end{table*}
%
%TODO discussion on why RMSE is actually better for the smaller datasets
